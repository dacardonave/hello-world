{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Análisis de Variables Predictoras vs 'canal_final'\n",
    "\n",
    "Este notebook realiza el análisis variable a variable. La idea es:\n",
    "1. Obtener los nombres de las columnas leyendo las primeras 4 filas del archivo.\n",
    "2. Para cada variable predictora (excluyendo 'canal_final'):\n",
    "   - Cargar la variable y la variable respuesta.\n",
    "   - Para variables **numéricas**:\n",
    "     - Realizar un binning (pd.qcut) y, a partir de la versión binned, calcular la tabla de contingencia para obtener las métricas Chi2, Chi2 p‑valor y Cramer’s V.\n",
    "     - Calcular también métricas de ANOVA (F, p) y Eta Squared usando la variable original.\n",
    "   - Para variables **categóricas**:\n",
    "     - Obtener la lista de categorías y calcular la tabla de contingencia para obtener Chi2, p‑valor y Cramer’s V.\n",
    "   - Entrenar un árbol de decisión sencillo (con `class_weight='balanced'`) para cada variable vs el target.  \n",
    "     Para variables numéricas se usa la versión binned, y se extrae la métrica *weighted avg f1_score*.\n",
    "3. Al final, se genera un DataFrame con una fila por variable y las métricas calculadas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Función para calcular Eta Squared para variables numéricas\n",
    "def calcular_eta_squared(x, y):\n",
    "    overall_mean = np.mean(x)\n",
    "    grupos = [x[y == cat] for cat in np.unique(y)]\n",
    "    ss_between = sum(len(g) * (np.mean(g) - overall_mean) ** 2 for g in grupos)\n",
    "    ss_total = sum((xi - overall_mean) ** 2 for xi in x)\n",
    "    return ss_between / ss_total if ss_total != 0 else np.nan\n",
    "\n",
    "# Función para evaluar una variable en relación con el target 'canal_final'\n",
    "def evaluate_variable(x, y, var_tipo, n_bins=10):\n",
    "    \"\"\"\n",
    "    Calcula métricas para una variable predictora frente a 'canal_final'.\n",
    "    \n",
    "    Parámetros:\n",
    "      - x: Serie de la variable predictora.\n",
    "      - y: Serie del target ('canal_final').\n",
    "      - var_tipo: \"numérica\" o \"categórica\".\n",
    "      - n_bins: Número de bins para variables numéricas.\n",
    "    \n",
    "    Retorna un diccionario con las métricas:\n",
    "      - bins_grupos, ANOVA_F, ANOVA_p, Eta_Squared,\n",
    "        Chi2, Chi2_p, Cramers_V, weighted_f1\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"bins_grupos\": \"no aplica\",\n",
    "        \"ANOVA_F\": \"no aplica\",\n",
    "        \"ANOVA_p\": \"no aplica\",\n",
    "        \"Eta_Squared\": \"no aplica\",\n",
    "        \"Chi2\": \"no aplica\",\n",
    "        \"Chi2_p\": \"no aplica\",\n",
    "        \"Cramers_V\": \"no aplica\",\n",
    "        \"weighted_f1\": \"no aplica\"\n",
    "    }\n",
    "    \n",
    "    # Para la variable que se usará en el árbol de decisión:\n",
    "    # Para numéricas se usará la versión binned; para categóricas, la original.\n",
    "    if var_tipo == \"numérica\":\n",
    "        # Binning: usamos pd.qcut\n",
    "        try:\n",
    "            x_binned, bins = pd.qcut(x, q=n_bins, duplicates='drop', retbins=True)\n",
    "            metrics[\"bins_grupos\"] = bins.tolist()\n",
    "        except Exception as e:\n",
    "            x_binned = None\n",
    "            metrics[\"bins_grupos\"] = \"no aplica\"\n",
    "        \n",
    "        # Métricas de ANOVA: usando la variable original\n",
    "        grupos = []\n",
    "        for cat in np.unique(y):\n",
    "            group_data = x[y == cat]\n",
    "            grupos.append(group_data.dropna())\n",
    "        if len(grupos) > 1:\n",
    "            try:\n",
    "                f_val, p_val = stats.f_oneway(*grupos)\n",
    "                metrics[\"ANOVA_F\"] = f_val if not np.isnan(f_val) else \"no aplica\"\n",
    "                metrics[\"ANOVA_p\"] = p_val if not np.isnan(p_val) else \"no aplica\"\n",
    "            except Exception as e:\n",
    "                metrics[\"ANOVA_F\"] = \"no aplica\"\n",
    "                metrics[\"ANOVA_p\"] = \"no aplica\"\n",
    "        else:\n",
    "            metrics[\"ANOVA_F\"] = \"no aplica\"\n",
    "            metrics[\"ANOVA_p\"] = \"no aplica\"\n",
    "        \n",
    "        # Calcular Eta Squared\n",
    "        try:\n",
    "            eta2 = calcular_eta_squared(x, y)\n",
    "            metrics[\"Eta_Squared\"] = eta2 if not np.isnan(eta2) else \"no aplica\"\n",
    "        except Exception as e:\n",
    "            metrics[\"Eta_Squared\"] = \"no aplica\"\n",
    "        \n",
    "        # Con la variable binned se calculan las métricas de Chi-cuadrado:\n",
    "        if x_binned is not None:\n",
    "            try:\n",
    "                contingency = pd.crosstab(x_binned, y)\n",
    "                if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                    chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                    metrics[\"Chi2\"] = chi2 if not np.isnan(chi2) else \"no aplica\"\n",
    "                    metrics[\"Chi2_p\"] = p if not np.isnan(p) else \"no aplica\"\n",
    "                    n = contingency.sum().sum()\n",
    "                    min_dim = min(contingency.shape) - 1\n",
    "                    if n * min_dim != 0:\n",
    "                        cramer_v = np.sqrt(chi2 / (n * min_dim))\n",
    "                        metrics[\"Cramers_V\"] = cramer_v\n",
    "                    else:\n",
    "                        metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "                else:\n",
    "                    metrics[\"Chi2\"] = \"no aplica\"\n",
    "                    metrics[\"Chi2_p\"] = \"no aplica\"\n",
    "                    metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "            except Exception as e:\n",
    "                metrics[\"Chi2\"] = \"no aplica\"\n",
    "                metrics[\"Chi2_p\"] = \"no aplica\"\n",
    "                metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "        else:\n",
    "            metrics[\"Chi2\"] = \"no aplica\"\n",
    "            metrics[\"Chi2_p\"] = \"no aplica\"\n",
    "            metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "        \n",
    "        # Para el árbol, usaremos la variable binned (si existe) convertida a string\n",
    "        if x_binned is not None:\n",
    "            X_feature = x_binned.astype(str)\n",
    "        else:\n",
    "            X_feature = x.astype(str)\n",
    "    \n",
    "    else:  # Variable categórica\n",
    "        try:\n",
    "            unique_vals = sorted(x.dropna().unique().tolist())\n",
    "            metrics[\"bins_grupos\"] = unique_vals\n",
    "        except Exception as e:\n",
    "            metrics[\"bins_grupos\"] = \"no aplica\"\n",
    "        \n",
    "        # Las métricas ANOVA y Eta Squared no aplican para variables categóricas\n",
    "        metrics[\"ANOVA_F\"] = \"no aplica\"\n",
    "        metrics[\"ANOVA_p\"] = \"no aplica\"\n",
    "        metrics[\"Eta_Squared\"] = \"no aplica\"\n",
    "        \n",
    "        # Calcular Chi-cuadrado, p y Cramer’s V directamente\n",
    "        try:\n",
    "            contingency = pd.crosstab(x, y)\n",
    "            if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                metrics[\"Chi2\"] = chi2 if not np.isnan(chi2) else \"no aplica\"\n",
    "                metrics[\"Chi2_p\"] = p if not np.isnan(p) else \"no aplica\"\n",
    "                n = contingency.sum().sum()\n",
    "                min_dim = min(contingency.shape) - 1\n",
    "                if n * min_dim != 0:\n",
    "                    cramer_v = np.sqrt(chi2 / (n * min_dim))\n",
    "                    metrics[\"Cramers_V\"] = cramer_v\n",
    "                else:\n",
    "                    metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "            else:\n",
    "                metrics[\"Chi2\"] = \"no aplica\"\n",
    "                metrics[\"Chi2_p\"] = \"no aplica\"\n",
    "                metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "        except Exception as e:\n",
    "            metrics[\"Chi2\"] = \"no aplica\"\n",
    "            metrics[\"Chi2_p\"] = \"no aplica\"\n",
    "            metrics[\"Cramers_V\"] = \"no aplica\"\n",
    "        \n",
    "        # Para el árbol, se utiliza la variable original convertida a string\n",
    "        X_feature = x.astype(str)\n",
    "    \n",
    "    # Entrenar un árbol de decisión sencillo con class_weight='balanced'\n",
    "    try:\n",
    "        # Se deben codificar tanto la feature como el target\n",
    "        le_feature = LabelEncoder()\n",
    "        X_encoded = le_feature.fit_transform(X_feature)\n",
    "        X_encoded = X_encoded.reshape(-1, 1)\n",
    "        \n",
    "        le_target = LabelEncoder()\n",
    "        y_encoded = le_target.fit_transform(y)\n",
    "        \n",
    "        clf = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "        clf.fit(X_encoded, y_encoded)\n",
    "        y_pred = clf.predict(X_encoded)\n",
    "        f1 = f1_score(y_encoded, y_pred, average='weighted')\n",
    "        metrics[\"weighted_f1\"] = f1\n",
    "    except Exception as e:\n",
    "        metrics[\"weighted_f1\"] = \"no aplica\"\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Función principal que:\n",
    "# 1. Lee las primeras 4 filas del archivo para obtener los nombres de columnas.\n",
    "# 2. Itera sobre cada variable predictora (excluyendo 'canal_final').\n",
    "# 3. Para cada variable, carga dicha columna y 'canal_final' y calcula todas las métricas.\n",
    "def main_analysis(file_path, target_column='canal_final', n_bins=10):\n",
    "    # Leer las primeras 4 filas para obtener los nombres de las columnas\n",
    "    df_head = pd.read_csv(file_path, nrows=4)\n",
    "    all_columns = df_head.columns.tolist()\n",
    "    \n",
    "    # Se excluye la columna target para las variables predictoras\n",
    "    predictor_columns = [col for col in all_columns if col != target_column]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterar variable a variable\n",
    "    for col in predictor_columns:\n",
    "        try:\n",
    "            # Cargar solo la columna predictora y la columna target\n",
    "            df_var = pd.read_csv(file_path, usecols=[col, target_column])\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la columna {col}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Eliminar filas con datos faltantes en la variable o en el target\n",
    "        df_var = df_var.dropna(subset=[col, target_column])\n",
    "        \n",
    "        # Determinar el tipo de variable\n",
    "        if np.issubdtype(df_var[col].dtype, np.number):\n",
    "            var_tipo = \"numérica\"\n",
    "        else:\n",
    "            var_tipo = \"categórica\"\n",
    "        \n",
    "        # Calcular todas las métricas para la variable actual\n",
    "        metrics = evaluate_variable(df_var[col], df_var[target_column], var_tipo, n_bins=n_bins)\n",
    "        \n",
    "        result_row = {\n",
    "            \"variable\": col,\n",
    "            \"tipo\": var_tipo,\n",
    "            \"bins_grupos\": metrics[\"bins_grupos\"],\n",
    "            \"ANOVA_F\": metrics[\"ANOVA_F\"],\n",
    "            \"ANOVA_p\": metrics[\"ANOVA_p\"],\n",
    "            \"Eta_Squared\": metrics[\"Eta_Squared\"],\n",
    "            \"Chi2\": metrics[\"Chi2\"],\n",
    "            \"Chi2_p\": metrics[\"Chi2_p\"],\n",
    "            \"Cramers_V\": metrics[\"Cramers_V\"],\n",
    "            \"weighted_f1\": metrics[\"weighted_f1\"]\n",
    "        }\n",
    "        results.append(result_row)\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# file_path = 'ruta_al_archivo.csv'\n",
    "# df_resultado_final = main_analysis(file_path, target_column='canal_final', n_bins=10)\n",
    "# print(df_resultado_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones\n",
    "\n",
    "Binning y Métricas:\n",
    "Para variables numéricas se realiza un binning y se calcula la tabla de contingencia para extraer Chi2, p‑valor y Cramer’s V. Además, se mantienen las métricas de ANOVA y Eta Squared utilizando la variable original.\n",
    "Árbol de Decisión:\n",
    "Se entrena un árbol de decisión sencillo (con class_weight='balanced') para cada variable predictora (usando la versión binned en el caso numérico) y se calcula el weighted avg f1_score, lo que brinda una medida adicional del poder discriminativo de la variable.\n",
    "Procesamiento Iterativo:\n",
    "Se realiza una lectura inicial de 4 filas para obtener la estructura del DataFrame y luego se procesa variable a variable, lo que permite trabajar con archivos muy grandes sin cargar todas las columnas de una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
