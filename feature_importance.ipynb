{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para variables numéricas:\n",
    "\n",
    "ANOVA (F-Statistic y p-valor): Para verificar si hay diferencias significativas en la media de la variable numérica entre las 7 categorías.\n",
    "\n",
    "Gini impurity: Utilizando un árbol de decisión para ver qué tan bien la variable segmenta la variable objetivo.\n",
    "\n",
    "Kruskal-Wallis: Alternativa no paramétrica a ANOVA cuando la normalidad no está garantizada.\n",
    "\n",
    "Para variables categóricas:\n",
    "\n",
    "Chi-cuadrado (χ² y p-valor): Para medir independencia entre la variable categórica y la variable objetivo.\n",
    "\n",
    "IV (Information Value): Para medir la capacidad de la variable para discriminar entre categorías.\n",
    "\n",
    "Entropía de Shannon: Para evaluar la incertidumbre de la variable respecto a la variable objetivo.\n",
    "\n",
    "Cramer’s V: Para medir la fuerza de asociación entre la variable y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, chi2_contingency, entropy, kruskal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def calculate_gini(x, y):\n",
    "    \"\"\"Calcula la importancia de Gini usando un árbol de decisión simple.\"\"\"\n",
    "    if x.nunique() > 1:  # Solo calcular si hay más de un valor único\n",
    "        clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "        clf.fit(x.values.reshape(-1, 1), y)\n",
    "        return clf.feature_importances_[0]\n",
    "    return np.nan\n",
    "\n",
    "def information_value(x, y):\n",
    "    \"\"\"Calcula el Information Value (IV) para una variable categórica.\"\"\"\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "    grouped = df.groupby('x')['y'].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # Verificar si hay información suficiente\n",
    "    if grouped.shape[1] < 2:  \n",
    "        return np.nan\n",
    "    \n",
    "    woe = np.log((grouped + 0.0001) / (1 - grouped + 0.0001))  # WoE\n",
    "    iv = (grouped - (1 - grouped)) * woe\n",
    "    return iv.sum().sum()\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calcula el coeficiente de Cramer para medir la asociación entre variables categóricas.\"\"\"\n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    \n",
    "    if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:\n",
    "        return np.nan  # No se puede calcular si hay muy pocas categorías\n",
    "    \n",
    "    chi2_val, _, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    min_dim = min(contingency_table.shape) - 1\n",
    "    return np.sqrt(chi2_val / (n * min_dim))\n",
    "\n",
    "def analyze_features(df, target_column):\n",
    "    results = []\n",
    "    y = df[target_column]  # La variable objetivo se mantiene categórica\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column == target_column:\n",
    "            continue\n",
    "        \n",
    "        x = df[column]\n",
    "        result = {'Variable': column, 'Tipo': str(x.dtype)}\n",
    "\n",
    "        # Si más del 95% de los valores son NaN, descartamos la variable\n",
    "        if x.isna().sum() / len(x) > 0.95:\n",
    "            result.update({'ANOVA_F': np.nan, 'Chi2': np.nan, 'IV': np.nan, \n",
    "                           'Gini': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            results.append(result)\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(x.dtype, np.number):  # Variables numéricas\n",
    "            groups = [x[y == cat].dropna() for cat in y.unique()]\n",
    "            unique_values_per_group = [len(set(g)) > 1 for g in groups]\n",
    "\n",
    "            if len(groups) > 1 and any(unique_values_per_group):  # Evitar errores en ANOVA y Kruskal\n",
    "                f_stat, p_value = f_oneway(*groups)\n",
    "                kw_stat, kw_p_value = kruskal(*groups)\n",
    "                result.update({'ANOVA_F': f_stat, 'ANOVA_p': p_value, 'Kruskal_H': kw_stat, 'Kruskal_p': kw_p_value})\n",
    "            else:\n",
    "                result.update({'ANOVA_F': np.nan, 'ANOVA_p': np.nan, 'Kruskal_H': np.nan, 'Kruskal_p': np.nan})\n",
    "            \n",
    "            result['Gini'] = calculate_gini(x.dropna(), y[x.notna()])\n",
    "\n",
    "        else:  # Variables categóricas\n",
    "            if x.nunique() < 50:  # Limitar para evitar problemas en tablas muy grandes\n",
    "                contingency_table = pd.crosstab(x, y)\n",
    "                \n",
    "                if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:  # Asegurar que hay suficientes datos\n",
    "                    chi2_val, p, _, _ = chi2_contingency(contingency_table)\n",
    "                    result.update({'Chi2': chi2_val, 'Chi2_p': p})\n",
    "                    result['IV'] = information_value(x, y)\n",
    "                    result['Cramer_V'] = cramers_v(x, y)\n",
    "                    result['Entropía'] = entropy(contingency_table.sum(axis=1), base=2)\n",
    "                else:\n",
    "                    result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            else:\n",
    "                result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, kruskal, chi2_contingency\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def calcular_métricas(df, target_col):\n",
    "    resultados = []\n",
    "    target = df[target_col]\n",
    "    \n",
    "    # Convertimos target a valores numéricos si es categórico\n",
    "    target_encoded, clases = pd.factorize(target)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == target_col:\n",
    "            continue  # Omitimos la variable objetivo\n",
    "\n",
    "        variable = df[col]\n",
    "        tipo_variable = \"numérica\" if np.issubdtype(variable.dtype, np.number) else \"categórica\"\n",
    "\n",
    "        # Inicializamos valores por defecto\n",
    "        anova_p = kruskal_p = chi2_p = info_mutua = gini = \"no aplica\"\n",
    "        bins = accuracy_por_clase = recall_por_clase = \"no aplica\"\n",
    "\n",
    "        if tipo_variable == \"numérica\":\n",
    "            temp_df = df[[col, target_col]].dropna()\n",
    "            grupos = [temp_df[temp_df[target_col] == clase][col] for clase in temp_df[target_col].unique()]\n",
    "\n",
    "            if all(len(grupo) > 1 for grupo in grupos):  # Asegurar que haya suficientes datos en cada grupo\n",
    "                try:\n",
    "                    anova_p = f_oneway(*grupos).pvalue  # ANOVA\n",
    "                except:\n",
    "                    anova_p = \"error\"\n",
    "\n",
    "                try:\n",
    "                    kruskal_p = kruskal(*grupos).pvalue  # Kruskal-Wallis\n",
    "                except:\n",
    "                    kruskal_p = \"error\"\n",
    "\n",
    "            # Información Mutua\n",
    "            info_mutua = mutual_info_classif(temp_df[[col]], temp_df[target_col], discrete_features=False)[0]\n",
    "\n",
    "        elif tipo_variable == \"categórica\":\n",
    "            temp_df = df[[col, target_col]].dropna()\n",
    "            \n",
    "            if temp_df[col].nunique() > 1:  # Asegurar que haya más de una categoría\n",
    "                try:\n",
    "                    tabla_contingencia = pd.crosstab(temp_df[col], temp_df[target_col])\n",
    "                    chi2_p = chi2_contingency(tabla_contingencia)[1]  # Prueba de chi-cuadrado\n",
    "                except:\n",
    "                    chi2_p = \"error\"\n",
    "\n",
    "                info_mutua = mutual_info_classif(temp_df[[col]], temp_df[target_col], discrete_features=True)[0]\n",
    "\n",
    "        # Modelo de árbol de decisión para calcular Gini, Accuracy y Recall\n",
    "        temp_df = df[[col, target_col]].dropna()\n",
    "        X = temp_df[[col]].copy()\n",
    "        y = temp_df[target_col]\n",
    "\n",
    "        if X.nunique().values[0] > 1:  # Solo entrenamos si hay más de una categoría\n",
    "            model = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "            X_encoded = pd.get_dummies(X) if tipo_variable == \"categórica\" else X  # Convertir categóricas a dummies\n",
    "            model.fit(X_encoded, y)\n",
    "\n",
    "            gini = 2 * model.tree_.impurity[0]  # Cálculo del índice de Gini\n",
    "            y_pred = model.predict(X_encoded)\n",
    "\n",
    "            accuracy_por_clase = {}\n",
    "            recall_por_clase = {}\n",
    "\n",
    "            for clase in clases:\n",
    "                mascara = (y == clase)\n",
    "                if mascara.sum() > 0:  # Evitar divisiones por cero\n",
    "                    accuracy_por_clase[clase] = accuracy_score(y[mascara], y_pred[mascara])\n",
    "                    recall_por_clase[clase] = recall_score(y[mascara], y_pred[mascara], average='macro', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"variable\": col,\n",
    "            \"tipo\": tipo_variable,\n",
    "            \"bins/grupos\": bins,\n",
    "            \"anova_p\": anova_p,\n",
    "            \"kruskal_p\": kruskal_p,\n",
    "            \"chi2_p\": chi2_p,\n",
    "            \"info_mutua\": info_mutua,\n",
    "            \"gini\": gini,\n",
    "            \"accuracy_por_clase\": accuracy_por_clase,\n",
    "            \"recall_por_clase\": recall_por_clase\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Cargar el dataset (reemplaza con tu archivo real)\n",
    "df = pd.read_csv(\"tu_archivo.csv\")  \n",
    "\n",
    "# Reemplaza 'target' con el nombre real de tu variable objetivo\n",
    "df_resultados = calcular_métricas(df, target_col='target')\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "df_resultados.to_csv(\"resultados_metricas.csv\", index=False)\n",
    "\n",
    "print(df_resultados.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
