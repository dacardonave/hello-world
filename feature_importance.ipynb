{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para variables numéricas:\n",
    "\n",
    "ANOVA (F-Statistic y p-valor): Para verificar si hay diferencias significativas en la media de la variable numérica entre las 7 categorías.\n",
    "\n",
    "Gini impurity: Utilizando un árbol de decisión para ver qué tan bien la variable segmenta la variable objetivo.\n",
    "\n",
    "Kruskal-Wallis: Alternativa no paramétrica a ANOVA cuando la normalidad no está garantizada.\n",
    "\n",
    "Para variables categóricas:\n",
    "\n",
    "Chi-cuadrado (χ² y p-valor): Para medir independencia entre la variable categórica y la variable objetivo.\n",
    "\n",
    "IV (Information Value): Para medir la capacidad de la variable para discriminar entre categorías.\n",
    "\n",
    "Entropía de Shannon: Para evaluar la incertidumbre de la variable respecto a la variable objetivo.\n",
    "\n",
    "Cramer’s V: Para medir la fuerza de asociación entre la variable y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, chi2_contingency, entropy, kruskal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def calculate_gini(x, y):\n",
    "    \"\"\"Calcula la importancia de Gini usando un árbol de decisión simple.\"\"\"\n",
    "    if x.nunique() > 1:  # Solo calcular si hay más de un valor único\n",
    "        clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "        clf.fit(x.values.reshape(-1, 1), y)\n",
    "        return clf.feature_importances_[0]\n",
    "    return np.nan\n",
    "\n",
    "def information_value(x, y):\n",
    "    \"\"\"Calcula el Information Value (IV) para una variable categórica.\"\"\"\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "    grouped = df.groupby('x')['y'].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # Verificar si hay información suficiente\n",
    "    if grouped.shape[1] < 2:  \n",
    "        return np.nan\n",
    "    \n",
    "    woe = np.log((grouped + 0.0001) / (1 - grouped + 0.0001))  # WoE\n",
    "    iv = (grouped - (1 - grouped)) * woe\n",
    "    return iv.sum().sum()\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calcula el coeficiente de Cramer para medir la asociación entre variables categóricas.\"\"\"\n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    \n",
    "    if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:\n",
    "        return np.nan  # No se puede calcular si hay muy pocas categorías\n",
    "    \n",
    "    chi2_val, _, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    min_dim = min(contingency_table.shape) - 1\n",
    "    return np.sqrt(chi2_val / (n * min_dim))\n",
    "\n",
    "def analyze_features(df, target_column):\n",
    "    results = []\n",
    "    y = df[target_column]  # La variable objetivo se mantiene categórica\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column == target_column:\n",
    "            continue\n",
    "        \n",
    "        x = df[column]\n",
    "        result = {'Variable': column, 'Tipo': str(x.dtype)}\n",
    "\n",
    "        # Si más del 95% de los valores son NaN, descartamos la variable\n",
    "        if x.isna().sum() / len(x) > 0.95:\n",
    "            result.update({'ANOVA_F': np.nan, 'Chi2': np.nan, 'IV': np.nan, \n",
    "                           'Gini': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            results.append(result)\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(x.dtype, np.number):  # Variables numéricas\n",
    "            groups = [x[y == cat].dropna() for cat in y.unique()]\n",
    "            unique_values_per_group = [len(set(g)) > 1 for g in groups]\n",
    "\n",
    "            if len(groups) > 1 and any(unique_values_per_group):  # Evitar errores en ANOVA y Kruskal\n",
    "                f_stat, p_value = f_oneway(*groups)\n",
    "                kw_stat, kw_p_value = kruskal(*groups)\n",
    "                result.update({'ANOVA_F': f_stat, 'ANOVA_p': p_value, 'Kruskal_H': kw_stat, 'Kruskal_p': kw_p_value})\n",
    "            else:\n",
    "                result.update({'ANOVA_F': np.nan, 'ANOVA_p': np.nan, 'Kruskal_H': np.nan, 'Kruskal_p': np.nan})\n",
    "            \n",
    "            result['Gini'] = calculate_gini(x.dropna(), y[x.notna()])\n",
    "\n",
    "        else:  # Variables categóricas\n",
    "            if x.nunique() < 50:  # Limitar para evitar problemas en tablas muy grandes\n",
    "                contingency_table = pd.crosstab(x, y)\n",
    "                \n",
    "                if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:  # Asegurar que hay suficientes datos\n",
    "                    chi2_val, p, _, _ = chi2_contingency(contingency_table)\n",
    "                    result.update({'Chi2': chi2_val, 'Chi2_p': p})\n",
    "                    result['IV'] = information_value(x, y)\n",
    "                    result['Cramer_V'] = cramers_v(x, y)\n",
    "                    result['Entropía'] = entropy(contingency_table.sum(axis=1), base=2)\n",
    "                else:\n",
    "                    result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            else:\n",
    "                result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir categóricas a numéricas usando one-hot encoding\n",
    "if tipo_variable == \"categórica\":\n",
    "    X_encoded = pd.get_dummies(X, drop_first=True)  # Convertir en dummies\n",
    "else:\n",
    "    X_encoded = X  # Dejar las numéricas sin cambios\n",
    "\n",
    "# Verificar que la variable no tenga solo un valor único (para evitar errores en el modelo)\n",
    "if X_encoded.nunique().values[0] > 1:  \n",
    "    model = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "    model.fit(X_encoded, y)\n",
    "\n",
    "    gini = 2 * model.tree_.impurity[0]  # Cálculo del índice de Gini\n",
    "    y_pred = model.predict(X_encoded)\n",
    "\n",
    "    accuracy_por_clase = {}\n",
    "    recall_por_clase = {}\n",
    "\n",
    "    for clase in clases:\n",
    "        mascara = (y == clase)\n",
    "        if mascara.sum() > 0:  # Evitar divisiones por cero\n",
    "            accuracy_por_clase[clase] = accuracy_score(y[mascara], y_pred[mascara])\n",
    "            recall_por_clase[clase] = recall_score(y[mascara], y_pred[mascara], average='macro', zero_division=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
