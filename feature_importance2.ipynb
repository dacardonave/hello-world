{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para variables numéricas:\n",
    "\n",
    "ANOVA (F-Statistic y p-valor): Para verificar si hay diferencias significativas en la media de la variable numérica entre las 7 categorías.\n",
    "\n",
    "Gini impurity: Utilizando un árbol de decisión para ver qué tan bien la variable segmenta la variable objetivo.\n",
    "\n",
    "Kruskal-Wallis: Alternativa no paramétrica a ANOVA cuando la normalidad no está garantizada.\n",
    "\n",
    "Para variables categóricas:\n",
    "\n",
    "Chi-cuadrado (χ² y p-valor): Para medir independencia entre la variable categórica y la variable objetivo.\n",
    "\n",
    "IV (Information Value): Para medir la capacidad de la variable para discriminar entre categorías.\n",
    "\n",
    "Entropía de Shannon: Para evaluar la incertidumbre de la variable respecto a la variable objetivo.\n",
    "\n",
    "Cramer’s V: Para medir la fuerza de asociación entre la variable y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, chi2_contingency, entropy, kruskal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def calculate_gini(x, y):\n",
    "    \"\"\"Calcula la importancia de Gini usando un árbol de decisión simple.\"\"\"\n",
    "    if x.nunique() > 1:  # Solo calcular si hay más de un valor único\n",
    "        clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "        clf.fit(x.values.reshape(-1, 1), y)\n",
    "        return clf.feature_importances_[0]\n",
    "    return np.nan\n",
    "\n",
    "def information_value(x, y):\n",
    "    \"\"\"Calcula el Information Value (IV) para una variable categórica.\"\"\"\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "    grouped = df.groupby('x')['y'].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # Verificar si hay información suficiente\n",
    "    if grouped.shape[1] < 2:  \n",
    "        return np.nan\n",
    "    \n",
    "    woe = np.log((grouped + 0.0001) / (1 - grouped + 0.0001))  # WoE\n",
    "    iv = (grouped - (1 - grouped)) * woe\n",
    "    return iv.sum().sum()\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calcula el coeficiente de Cramer para medir la asociación entre variables categóricas.\"\"\"\n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    \n",
    "    if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:\n",
    "        return np.nan  # No se puede calcular si hay muy pocas categorías\n",
    "    \n",
    "    chi2_val, _, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    min_dim = min(contingency_table.shape) - 1\n",
    "    return np.sqrt(chi2_val / (n * min_dim))\n",
    "\n",
    "def analyze_features(df, target_column):\n",
    "    results = []\n",
    "    y = df[target_column]  # La variable objetivo se mantiene categórica\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column == target_column:\n",
    "            continue\n",
    "        \n",
    "        x = df[column]\n",
    "        result = {'Variable': column, 'Tipo': str(x.dtype)}\n",
    "\n",
    "        # Si más del 95% de los valores son NaN, descartamos la variable\n",
    "        if x.isna().sum() / len(x) > 0.95:\n",
    "            result.update({'ANOVA_F': np.nan, 'Chi2': np.nan, 'IV': np.nan, \n",
    "                           'Gini': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            results.append(result)\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(x.dtype, np.number):  # Variables numéricas\n",
    "            groups = [x[y == cat].dropna() for cat in y.unique()]\n",
    "            unique_values_per_group = [len(set(g)) > 1 for g in groups]\n",
    "\n",
    "            if len(groups) > 1 and any(unique_values_per_group):  # Evitar errores en ANOVA y Kruskal\n",
    "                f_stat, p_value = f_oneway(*groups)\n",
    "                kw_stat, kw_p_value = kruskal(*groups)\n",
    "                result.update({'ANOVA_F': f_stat, 'ANOVA_p': p_value, 'Kruskal_H': kw_stat, 'Kruskal_p': kw_p_value})\n",
    "            else:\n",
    "                result.update({'ANOVA_F': np.nan, 'ANOVA_p': np.nan, 'Kruskal_H': np.nan, 'Kruskal_p': np.nan})\n",
    "            \n",
    "            result['Gini'] = calculate_gini(x.dropna(), y[x.notna()])\n",
    "\n",
    "        else:  # Variables categóricas\n",
    "            if x.nunique() < 50:  # Limitar para evitar problemas en tablas muy grandes\n",
    "                contingency_table = pd.crosstab(x, y)\n",
    "                \n",
    "                if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:  # Asegurar que hay suficientes datos\n",
    "                    chi2_val, p, _, _ = chi2_contingency(contingency_table)\n",
    "                    result.update({'Chi2': chi2_val, 'Chi2_p': p})\n",
    "                    result['IV'] = information_value(x, y)\n",
    "                    result['Cramer_V'] = cramers_v(x, y)\n",
    "                    result['Entropía'] = entropy(contingency_table.sum(axis=1), base=2)\n",
    "                else:\n",
    "                    result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "            else:\n",
    "                result.update({'Chi2': np.nan, 'Chi2_p': np.nan, 'IV': np.nan, 'Cramer_V': np.nan, 'Entropía': np.nan})\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, kruskal, chi2_contingency\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def calcular_métricas(df, target_col):\n",
    "    resultados = []\n",
    "    target = df[target_col]\n",
    "\n",
    "    # Convertimos target a valores numéricos si es categórico\n",
    "    target_encoded, clases = pd.factorize(target)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == target_col:\n",
    "            continue  # Omitimos la variable objetivo\n",
    "\n",
    "        variable = df[col]\n",
    "        tipo_variable = \"numérica\" if np.issubdtype(variable.dtype, np.number) else \"categórica\"\n",
    "\n",
    "        # Inicializamos valores por defecto\n",
    "        anova_p = kruskal_p = chi2_p = info_mutua = gini = \"no aplica\"\n",
    "        bins = accuracy_por_clase = recall_por_clase = \"no aplica\"\n",
    "\n",
    "        if tipo_variable == \"numérica\":\n",
    "            temp_df = df[[col, target_col]].dropna()\n",
    "            grupos = [temp_df[temp_df[target_col] == clase][col] for clase in temp_df[target_col].unique()]\n",
    "\n",
    "            if all(len(grupo) > 1 for grupo in grupos):  # Asegurar que haya suficientes datos en cada grupo\n",
    "                try:\n",
    "                    anova_p = f_oneway(*grupos).pvalue  # ANOVA\n",
    "                except:\n",
    "                    anova_p = \"error\"\n",
    "\n",
    "                try:\n",
    "                    kruskal_p = kruskal(*grupos).pvalue  # Kruskal-Wallis\n",
    "                except:\n",
    "                    kruskal_p = \"error\"\n",
    "\n",
    "            # Información Mutua\n",
    "            info_mutua = mutual_info_classif(temp_df[[col]], temp_df[target_col], discrete_features=False)[0]\n",
    "\n",
    "        elif tipo_variable == \"categórica\":\n",
    "            temp_df = df[[col, target_col]].dropna()\n",
    "\n",
    "            if temp_df[col].nunique() > 1:  # Asegurar que haya más de una categoría\n",
    "                try:\n",
    "                    tabla_contingencia = pd.crosstab(temp_df[col], temp_df[target_col])\n",
    "                    chi2_p = chi2_contingency(tabla_contingencia)[1]  # Prueba de chi-cuadrado\n",
    "                except:\n",
    "                    chi2_p = \"error\"\n",
    "\n",
    "                info_mutua = mutual_info_classif(temp_df[[col]], temp_df[target_col], discrete_features=True)[0]\n",
    "\n",
    "        # Modelo de árbol de decisión para calcular Gini, Accuracy y Recall\n",
    "        temp_df = df[[col, target_col]].dropna()\n",
    "        X = temp_df[[col]].copy()\n",
    "        y = temp_df[target_col]\n",
    "\n",
    "        # Convertir categóricas a numéricas usando one-hot encoding\n",
    "        if tipo_variable == \"categórica\":\n",
    "            X_encoded = pd.get_dummies(X, drop_first=True)  # Convertir en dummies\n",
    "        else:\n",
    "            X_encoded = X  # Dejar las numéricas sin cambios\n",
    "\n",
    "        # Verificar que la variable no tenga solo un valor único (para evitar errores en el modelo)\n",
    "        if X_encoded.nunique().values[0] > 1:\n",
    "            model = DecisionTreeClassifier(max_depth=1, random_state=42, class_weight='balanced')\n",
    "            model.fit(X_encoded, y)\n",
    "\n",
    "            gini = 2 * model.tree_.impurity[0]  # Cálculo del índice de Gini\n",
    "            y_pred = model.predict(X_encoded)\n",
    "\n",
    "            accuracy_por_clase = {}\n",
    "            recall_por_clase = {}\n",
    "\n",
    "            for i, clase in enumerate(clases):\n",
    "                mascara = (y == i)\n",
    "                if mascara.sum() > 0:  # Evitar divisiones por cero\n",
    "                    accuracy_por_clase[clase] = accuracy_score(y[mascara], y_pred[mascara])\n",
    "                    recall_por_clase[clase] = recall_score(y[mascara], y_pred[mascara], average='macro', zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            \"variable\": col,\n",
    "            \"tipo\": tipo_variable,\n",
    "            \"bins/grupos\": bins,\n",
    "            \"anova_p\": anova_p,\n",
    "            \"kruskal_p\": kruskal_p,\n",
    "            \"chi2_p\": chi2_p,\n",
    "            \"info_mutua\": info_mutua,\n",
    "            \"gini\": gini,\n",
    "            \"accuracy_por_clase\": accuracy_por_clase,\n",
    "            \"recall_por_clase\": recall_por_clase\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Cargar el dataset (reemplaza con tu archivo real)\n",
    "df = pd.read_csv(\"tu_archivo.csv\")  \n",
    "\n",
    "# Reemplaza 'target' con el nombre real de tu variable objetivo\n",
    "df_resultados = calcular_métricas(df, target_col='canal_final')\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "df_resultados.to_csv(\"resultados_metricas.csv\", index=False)\n",
    "\n",
    "print(df_resultados.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def calcular_eta_squared(x, y):\n",
    "    \"\"\"\n",
    "    Calcula el coeficiente eta squared para medir la asociación\n",
    "    entre una variable numérica (x) y una categórica (y).\n",
    "    \"\"\"\n",
    "    overall_mean = np.mean(x)\n",
    "    grupos = [x[y == cat] for cat in np.unique(y)]\n",
    "    ss_between = sum(len(g) * (np.mean(g) - overall_mean) ** 2 for g in grupos)\n",
    "    ss_total = sum((xi - overall_mean) ** 2 for xi in x)\n",
    "    return ss_between / ss_total if ss_total != 0 else np.nan\n",
    "\n",
    "def evaluar_variables(df, target_col, n_bins=10, incluir_bins=True):\n",
    "    \"\"\"\n",
    "    Evalúa cada variable predictora en relación con la variable objetivo,\n",
    "    retornando un DataFrame con una columna por cada métrica.\n",
    "    \n",
    "    Parámetros:\n",
    "      - df: DataFrame que contiene las variables predictoras y la variable target.\n",
    "      - target_col: Nombre de la columna target (variable respuesta categórica).\n",
    "      - n_bins: Número de bins a usar para variables numéricas.\n",
    "      - incluir_bins: Si es True, se incluye la columna de bins/grupos en la salida.\n",
    "      \n",
    "    Retorna:\n",
    "      - DataFrame con columnas: 'variable', 'tipo', 'bins/grupos', 'ANOVA_F',\n",
    "        'ANOVA_p', 'Eta_Squared', 'Chi2', 'Chi2_p', \"Cramers_V\"\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        \n",
    "        col_data = df[col]\n",
    "        # Determinar el tipo de variable (numérica o categórica)\n",
    "        if np.issubdtype(col_data.dtype, np.number):\n",
    "            var_tipo = 'numérica'\n",
    "        else:\n",
    "            var_tipo = 'categórica'\n",
    "        \n",
    "        # Inicializamos las columnas de resultados\n",
    "        bins_grupos = None  # Aquí se guardarán los bins o grupos (si se desea incluir)\n",
    "        ANOVA_F = \"no aplica\"\n",
    "        ANOVA_p = \"no aplica\"\n",
    "        Eta_Squared = \"no aplica\"\n",
    "        Chi2 = \"no aplica\"\n",
    "        Chi2_p = \"no aplica\"\n",
    "        Cramers_V = \"no aplica\"\n",
    "        \n",
    "        if var_tipo == 'numérica':\n",
    "            # Binning usando pd.qcut para dividir en cuantiles\n",
    "            try:\n",
    "                _, bins = pd.qcut(col_data, q=n_bins, duplicates='drop', retbins=True)\n",
    "                bins_grupos = bins.tolist() if incluir_bins else None\n",
    "            except Exception as e:\n",
    "                bins_grupos = \"no aplica\"\n",
    "            \n",
    "            # Agrupar la variable según las categorías del target\n",
    "            grupos = []\n",
    "            for cat in df[target_col].unique():\n",
    "                grupos.append(col_data[df[target_col] == cat].dropna())\n",
    "            \n",
    "            # Calcular ANOVA F y p-valor si hay más de un grupo\n",
    "            if len(grupos) > 1:\n",
    "                try:\n",
    "                    f_val, p_val = stats.f_oneway(*grupos)\n",
    "                    ANOVA_F = f_val if not np.isnan(f_val) else \"no aplica\"\n",
    "                    ANOVA_p = p_val if not np.isnan(p_val) else \"no aplica\"\n",
    "                except Exception as e:\n",
    "                    ANOVA_F, ANOVA_p = \"no aplica\", \"no aplica\"\n",
    "            \n",
    "            # Calcular el eta squared\n",
    "            try:\n",
    "                mask = col_data.notnull() & df[target_col].notnull()\n",
    "                eta2 = calcular_eta_squared(col_data[mask], df[target_col][mask])\n",
    "                Eta_Squared = eta2 if not np.isnan(eta2) else \"no aplica\"\n",
    "            except Exception as e:\n",
    "                Eta_Squared = \"no aplica\"\n",
    "                \n",
    "        else:  # Variable categórica\n",
    "            # Los grupos son las categorías únicas\n",
    "            try:\n",
    "                bins_grupos = sorted(col_data.dropna().unique().tolist()) if incluir_bins else None\n",
    "            except Exception as e:\n",
    "                bins_grupos = \"no aplica\"\n",
    "            \n",
    "            # Crear la tabla de contingencia entre la variable y el target\n",
    "            try:\n",
    "                tabla = pd.crosstab(col_data, df[target_col])\n",
    "                if not tabla.empty:\n",
    "                    chi2, p, dof, expected = stats.chi2_contingency(tabla)\n",
    "                    Chi2 = chi2 if not np.isnan(chi2) else \"no aplica\"\n",
    "                    Chi2_p = p if not np.isnan(p) else \"no aplica\"\n",
    "                    n = tabla.sum().sum()\n",
    "                    min_dim = min(tabla.shape) - 1\n",
    "                    if n * min_dim != 0:\n",
    "                        Cramers_V = np.sqrt(chi2 / (n * min_dim))\n",
    "                    else:\n",
    "                        Cramers_V = \"no aplica\"\n",
    "                else:\n",
    "                    Chi2, Chi2_p, Cramers_V = \"no aplica\", \"no aplica\", \"no aplica\"\n",
    "            except Exception as e:\n",
    "                Chi2, Chi2_p, Cramers_V = \"no aplica\", \"no aplica\", \"no aplica\"\n",
    "        \n",
    "        resultados.append({\n",
    "            'variable': col,\n",
    "            'tipo': var_tipo,\n",
    "            'bins/grupos': bins_grupos,\n",
    "            'ANOVA_F': ANOVA_F,\n",
    "            'ANOVA_p': ANOVA_p,\n",
    "            'Eta_Squared': Eta_Squared,\n",
    "            'Chi2': Chi2,\n",
    "            'Chi2_p': Chi2_p,\n",
    "            \"Cramers_V\": Cramers_V\n",
    "        })\n",
    "    \n",
    "    df_resultado = pd.DataFrame(resultados)\n",
    "    \n",
    "    # Si no se desea incluir la columna de bins/grupos, la removemos\n",
    "    if not incluir_bins:\n",
    "        df_resultado.drop(columns=['bins/grupos'], inplace=True)\n",
    "    \n",
    "    return df_resultado\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Supongamos que tienes un DataFrame \"df\" y la variable target se llama \"target\".\n",
    "# Para incluir los bins/grupos:\n",
    "# df_resultado = evaluar_variables(df, target_col='target', n_bins=10, incluir_bins=True)\n",
    "#\n",
    "# Para omitir la columna de bins/grupos (tabla más limpia):\n",
    "# df_resultado = evaluar_variables(df, target_col='target', n_bins=10, incluir_bins=False)\n",
    "#\n",
    "# print(df_resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
